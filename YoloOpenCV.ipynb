{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a COCO-pretrained YOLOv8n model\n",
    "#that will create a file called yolov8n that we will use later for prediction\n",
    "model = YOLO(\"yolov8n.pt\", \"v8\")\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import cv2\n",
    "import pyttsx3  # This library will be used for voice notifications\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Microsoft Hortense Desktop - French ([])\n",
      "1: Microsoft Zira Desktop - English (United States) ([])\n"
     ]
    }
   ],
   "source": [
    "# Initialize voice engine\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "for i, voice in enumerate(voices):\n",
    "    print(f\"{i}: {voice.name} ({voice.languages})\")\n",
    "engine.setProperty('voice', voices[1].id)\n",
    "engine.setProperty('rate', 220)  # Speed of speech\n",
    "engine.setProperty('volume', 1)  # Volume level (0.0 to 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"objects.txt\", \"r\")# this file have all objects \n",
    "\n",
    "# reading the file\n",
    "data = my_file.read()\n",
    "# split when newline ('\\n') is seen\n",
    "class_list = data.split(\"\\n\")\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chair', 'Lamp', 'TrashBin', 'Tree', 'Car', 'Crosswalk', 'Person', 'Motorcycle', 'Bicycle', 'TraficLight', 'CrossSign', 'Dog', 'Wall', 'Bus', 'Cat', 'Barrier', 'DeliveryBox', 'FireHydrant', 'FallenSign', 'Fence', 'Hole_in_the_road', 'Road_cone', 'Open_manhole', 'Road_workahead', 'shopping_cart']\n"
     ]
    }
   ],
   "source": [
    "print(class_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just random colors for bounding boxes\n",
    "Boxes = []\n",
    "for i in range(len(class_list)):\n",
    "    r = random.randint(0, 255)\n",
    "    g = random.randint(0, 255)\n",
    "    b = random.randint(0, 255)\n",
    "    Boxes.append((b, g, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize video frames to optimise the run\n",
    "frame_wid = 1240\n",
    "frame_hyt = 920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(\"inference/videos/afriq0.MP4\") # this for a video\n",
    "# Ouvrir la caméra\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to announce the distance and object\n",
    "def announce_distance(class_name, distance):\n",
    "    def speak():\n",
    "        # Announce distance ranges\n",
    "        if distance < 1:\n",
    "            engine.say(f\"Warning! A {class_name} is in front of you, less than 1 meter away.\")\n",
    "        elif 1 <= distance < 2:\n",
    "            engine.say(f\"A {class_name} is in front of you, less than 2 meters away.\")\n",
    "        elif 2 <= distance < 3:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 2 to 3 meters away.\")\n",
    "        elif 3 <= distance < 4:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 3 meters away.\")\n",
    "        elif 4 <= distance < 5:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 4 meters away.\")\n",
    "        elif 5 <= distance < 6:\n",
    "            engine.say(f\"A {class_name} is in front of you, about 5 meters away.\")\n",
    "        else:\n",
    "            engine.say(f\"A {class_name} is far away, more than 5 meters.\")\n",
    "\n",
    "        # Run the speech engine\n",
    "        engine.runAndWait()\n",
    "\n",
    "    # Run the speaking function in a separate thread\n",
    "    threading.Thread(target=speak).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real widths of common objects (meters)\n",
    "REAL_WIDTHS = {\n",
    "    \"Chair\": 0.5,              # Largeur d'une chaise standard\n",
    "    \"Lamp\": 0.3,               # Pied de lampe ou lampe de rue\n",
    "    \"TrashBin\": 0.4,           # Poubelle de rue moyenne\n",
    "    \"Tree\": 0.5,               # Tronc d’arbre (non la couronne)\n",
    "    \"Car\": 1.8,                # Voiture moyenne\n",
    "    \"Crosswalk\": 2.5,          # Largeur typique d'un passage piéton\n",
    "    \"Person\": 0.5,             # Largeur des épaules\n",
    "    \"Motorcycle\": 0.8,         # Largeur moyenne d'une moto\n",
    "    \"Bicycle\": 0.6,            # Largeur guidon\n",
    "    \"TraficLight\": 0.3,        # Colonne ou feu lui-même\n",
    "    \"CrossSign\": 0.5,          # Panneau de signalisation piéton\n",
    "    \"Dog\": 0.4,                # Chien moyen\n",
    "    \"Wall\": 2.0,               # Largeur approximative d’un pan visible\n",
    "    \"Bus\": 2.5,                # Bus standard\n",
    "    \"Cat\": 0.25,               # Chat adulte\n",
    "    \"Barrier\": 1.2,            # Barrière de sécurité\n",
    "    \"DeliveryBox\": 0.5,        # Carton ou boîte de livraison\n",
    "    \"FireHydrant\": 0.4,        # Borne incendie standard\n",
    "    \"FallenSign\": 0.6,         # Panneau couché au sol\n",
    "    \"Fence\": 2.0,              # Largeur visible d'une barrière ou clôture\n",
    "    \"Hole_in_the_road\": 0.7,   # Diamètre moyen visible\n",
    "    \"Road_cone\": 0.3,          # Cône de signalisation\n",
    "    \"Open_manhole\": 0.6,       # Bouche d’égout ouverte\n",
    "    \"Road_workahead\": 1.0,     # Panneau ou zone de travaux\n",
    "    \"shopping_cart\": 0.55      # Largeur moyenne d’un chariot\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "FOCAL_LENGTH = 462  # You need to calculate this once using a known object\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"runs/detect/train/weights/best.pt\", \"v8\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame. Exiting ...\")\n",
    "        break\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    cv2.putText(overlay, \"Montrez un objet pour détecter...\", (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Perform object detection using YOLO model\n",
    "    detect_params = model.predict(source=[frame], conf=0.45, save=False)\n",
    "    DP = detect_params[0].cpu().numpy()\n",
    "\n",
    "    if len(DP) != 0:\n",
    "        if len(detect_params[0].boxes) != 0:\n",
    "            for i in range(len(detect_params[0].boxes)):\n",
    "                boxes = detect_params[0].boxes\n",
    "                box = boxes[i]\n",
    "                clsID = int(box.cls.cpu().numpy()[0])\n",
    "                conf = round(float(box.conf.cpu().numpy()[0]), 3)\n",
    "                bb = box.xyxy.cpu().numpy()[0]\n",
    "\n",
    "            class_name = class_list[clsID]\n",
    "\n",
    "            # ===================== CALCUL DISTANCE =====================\n",
    "            x1, y1, x2, y2 = map(int, bb)\n",
    "            object_roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            gray = cv2.cvtColor(object_roi, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            distance_text = \"Distance: ? m\"\n",
    "\n",
    "            if contours:\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                rect = cv2.minAreaRect(largest_contour)\n",
    "                object_width_pixels = min(rect[1])  \n",
    "\n",
    "                object_width_real = REAL_WIDTHS.get(class_name, None)\n",
    "\n",
    "                if object_width_real and object_width_pixels > 0:\n",
    "                    # Calculate the distance based on object width in pixels\n",
    "                    distance = (object_width_real * FOCAL_LENGTH) / object_width_pixels\n",
    "                    distance_text = f\"Distance: {round(distance, 2)} m\"\n",
    "                    #if(class_name!= \"person\"):\n",
    "                        # Announce the distance for this object\n",
    "                    announce_distance(class_name, distance)\n",
    "                    \n",
    "\n",
    "            # ===================== DESSINER =====================\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), Boxes[clsID], 3)\n",
    "\n",
    "            # Line 1: Object name + confidence\n",
    "            cv2.putText(frame, f\"{class_name} {conf}%\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "            # Line 2: Distance\n",
    "            cv2.putText(frame, distance_text, (x1, y1 + 25),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"ObjectDetection\", frame if len(DP) != 0 else overlay)\n",
    "\n",
    "    # Quit if 'q' is pressed or window is closed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    if cv2.getWindowProperty(\"ObjectDetection\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YoloEnv)",
   "language": "python",
   "name": "yoloenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
